% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/plus.R
\name{plus}
\alias{plus}
\title{main code for planning and learning in uncertain systems}
\usage{
plus(input, t = 100, Num_sim = 100, n_true, n_sample = 5, initial,
  P = (array(1, dim = length(input[[1]]))/length(input[[1]])))
}
\arguments{
\item{input:}{A list of transition (itself a list for all candidate models),
emission (itslef a list for all candidate models), reward matrix, and discount factor.}

\item{t:}{time horizon of the problem ; default = 100}

\item{Num_sim:}{Number of simulations replicates ; default = 100}

\item{n_true:}{index of the true model}

\item{n_sample:}{number of sample to use for planning under model uncertainty; default = 5}

\item{initial:}{initial belief state}

\item{P:}{prior probability of the models ; default is flat prior}
}
\value{
history_star_rew: history of rewards for the true model; dim = Num_sim * t

history_star_act: history of actions for the true model; dim = Num_sim * t

history_pl_rew: history of rewards for the plus model; dim = Num_sim * t

history_pl_act: history of actions for the plus model; dim = Num_sim * t

state_seq_mdp_pl: hidden state sequence of the plus model; dim = Num_sim * t

state_seq_mdp_star: hidden state sequence of the true model; dim = Num_sim * t

PP_pl: Posterior distribution of each candidate model at each time; dim = Num_sim * t * Num_model

av: list of alpha vectors for all candidate models; length = Num_Model

aa: list of actions corresponding to alpha vectors for all candidate models; length = Num_Model
}
\description{
main code for planning and learning in uncertain systems
}

