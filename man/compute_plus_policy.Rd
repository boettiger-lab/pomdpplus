% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compute_plus_policy.R
\name{compute_plus_policy}
\alias{compute_plus_policy}
\title{compute_plus_policy}
\usage{
compute_plus_policy(alphas, models, model_prior = NULL, state_prior = NULL,
  a0 = 1)
}
\arguments{
\item{alphas}{the alpha vectors for each model, as provided from \code{\link{sarsop_plus}}, which will otherwise be run each time if not provided.}

\item{models}{a list of lists, each of which gives the transition matrix, observation matrix and reward matrix for the model considered}

\item{model_prior}{Prior belief assigned to each model. uniform by default.}

\item{state_prior}{Prior belief that system is in state x_i before simulation starts}

\item{a0}{initial action (used to make the first observation, only relevant if observation depends on action)}
}
\value{
a data frame containing the policy and value associated with each possible observation
}
\description{
compute_plus_policy
}
\examples{
\dontrun{
source(system.file("examples/K_models.R", package="pomdpplus"))
alphas <- sarsop_plus(models, discount, precision = 1)
unif <- compute_plus_policy(alphas, models)
}
}

