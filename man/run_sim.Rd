% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/run_sim.R
\name{run_sim}
\alias{run_sim}
\title{function for running forward simulations for planning and learning under model uncertainty}
\usage{
run_sim(T, O, R, GAMMA, av, aa, n, Num_sim, t, N, init, n_sample,
  P = (array(1, dim = c(1, length(T)))/length(T)))
}
\arguments{
\item{T}{list of transition probabilities matrices for all candidate models; length = Num_model}

\item{O}{list of emission probabilities matrices for all candidate models; length = Num_model}

\item{R}{matrix of reward function}

\item{GAMMA}{discount factor}

\item{av}{list of alpha vectors for all candidate models; length = Num_Model}

\item{aa}{list of actions corresponding to alpha vectors for all candidate models; length = Num_Model}

\item{n}{index of the true model}

\item{Num_sim}{number of simulation replicates; default = 100}

\item{t}{time horizon of the simulaitons; default = 100}

\item{N}{number of candidate models}

\item{init}{initial belief of the states}

\item{n_sample}{number of samples used for planning; default = 5}

\item{P}{prior probability of the models ; default is flat prior}
}
\value{
history_star_rew history of rewards for the true model; dim = Num_sim * t

history_star_act history of actions for the true model; dim = Num_sim * t

history_pl_rew history of rewards for the plus model; dim = Num_sim * t

history_pl_act history of actions for the plus model; dim = Num_sim * t

state_seq_mdp_pl hidden state sequence of the plus model; dim = Num_sim * t

state_seq_mdp_star hidden state sequence of the true model; dim = Num_sim * t

PP_pl Posterior distribution of each candidate model at each time; dim = Num_sim * t * Num_model

av list of alpha vectors for all candidate models; length = Num_Model

aa list of actions corresponding to alpha vectors for all candidate models; length = Num_Model
}
\description{
function for running forward simulations for planning and learning under model uncertainty
}

