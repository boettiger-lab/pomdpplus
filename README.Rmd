---
title: "POMDP Planning and Learning in Uncertain Systems"
author: Carl Boettiger and Milad Memarzadeh
output: 
  github_document:
    html_preview: false
---

[![Build Status](https://drone.carlboettiger.info/api/badges/boettiger-lab/pomdpplus/status.svg)](https://drone.carlboettiger.info/boettiger-lab/pomdpplus)

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```


```{r}
library("pomdpplus")
library("ggplot2")
library("tidyr")
library("dplyr")
library("seewave")
```

Initialize a simple POMDP model for fisheries:

```{r}
states <- 1:10
actions <- states
observed_states <- states
reward_fn <-  function(x, a) pmin(x, a)
sigma_g <- 0.28
sigma_m <- 0.28
discount <- 0.95

## Create a list of functions, each function providing the model with different parameter combinations
p <- expand.grid(K = c(1,3), r = c(0.5, 1, 1.5))
models <- apply(p, 1, function(row) 
  function(x, h){
     s <- pmax(x - h, 0)
     s * exp(row[["r"]] * (1 - s / row[["K"]]) )
  })
    

matrices <- lapply(models, function(model) 
  appl::fisheries_matrices(states = states, actions = actions, 
                           observed_states = states, reward_fn = reward_fn,
                           f = model, sigma_g = sigma_g, sigma_m = sigma_m))

```

PLUS expects a list of Transition matrices and a separate list of Observation matrices. The reward matrix is the same for all models.


```{r}
T <- lapply(matrices, `[[`, "transition")
O <- lapply(matrices, `[[`, "observation")
reward <- matrices[[1]][["reward"]] # same for all models
```


## Applying to example data

```{r}
tuna <- read.csv("data/atlantic_bluefin.csv")
y = round(10 * tuna$biomass / max(tuna$biomass))
a = ceiling(10 * tuna$catch / max(tuna$biomass)) + 1
```



```{r}
system.time(
plus_results <- plus_seq(list(T, O, reward, discount), 
                     seq = seq,
                     Num_sim = 100, # Number of simulations to do 
                     n_sample = 16, # Subsample from the model list, if many models are present
                     initial = array(1, dim = length(states)) / length(states), # initial states prior, uniform 
                     precision = 1)
)

```


## Comparing to the correct model


Run PLUS:


```{r}
system.time(
plus_results <- plus(list(T, O, reward, discount), 
                     t = 100,      # Number of timesteps to run into the future
                     Num_sim = 20, # Number of simulations to do 
                     n_true = 3,   # Which index in the list represents the true model
                     n_sample = 16, # Subsample from the model list, if many models are present
                     initial = array(1, dim = length(states)) / length(states), # initial states prior, uniform 
                     P = (array(1,dim = length(models))/ length(models)),  # Model prior, uniform
                     precision = 1)
)
```



```{r}
## extract results to separate objects for convenience
df <- plus_results[["df"]]
posterior <- plus_results[["posterior"]]
```

Have we converged to the correct model?

```{r}
tail(posterior)
```


The data.frame `df` returns information about the simulations for both the true and learned `plus` models, allowing us to compare them. Here we compare the rewards garnered from the true and `plus` model over time, summarizing across the replicate simulations. 

```{r}
df %>% 
  select(time, sim, true_reward, plus_reward) %>%
  gather(model, value, -time, -sim) %>%
  ggplot(aes(time, value, group = model)) + 
    stat_summary(aes(color = model), geom="line", fun.y = mean, lwd = 1) +
    stat_summary(geom="ribbon", fun.data = mean_se, alpha = 0.1)
```


We can also compute the KL diveregnce to show the rate of learning:


```{r}
# delta function for true model distribution
h_star = array(0,dim = length(models)) 
h_star[n_true] = 1

## Fn for the base-2 KL divergence from true model, in a friendly format
kl2 <- function(value) seewave::kl.dist(value, h_star, base = 2)[[2]]

## Compute KL over models
P <- posterior %>% 
  gather(model, value, -time, -sim) %>%
  group_by(time, sim) %>% 
  summarise(kl = kl2(value))

## plot mean/se of KL over replicates
ggplot(P, aes(time, kl)) + 
    stat_summary(geom="line", fun.y = mean, lwd = 1) +
    stat_summary(geom="ribbon", fun.data = mean_se, alpha = 0.1)

```




