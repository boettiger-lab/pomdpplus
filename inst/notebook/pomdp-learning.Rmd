---
output:
  html_document: 
    keep_md: yes
    variant: markdown_github
---  



```{r}
library("MDPtoolbox")
library("appl")
library("ggplot2")
knitr::opts_chunk$set(cache = TRUE)
```

```{r}
source("pomdp_learning.R")
```


## Problem definition

```{r}
states <- 0:20
actions <- states
obs <- states

f <- function(x, h, r = 1, K = 15){
  s <- pmax(x - h, 0)
  s * exp(r * (1 - s / K) )
}

sigma_g <- sqrt(log(1 + 0.1 / 6)) # Scale the log-standard-deviation to result in similar variance to a uniform distribution of width 0.5
sigma_m <- sigma_g

reward_fn <- function(x,h) pmin(x,h)
discount <- 0.95
```


```{r}
m1 <- fisheries_matrices(states, actions, obs, reward_fn, f, sigma_g, sigma_m)

f <- function(x, h, r = 0.5, K = 15){
  s <- pmax(x - h, 0)
  s * exp(r * (1 - s / K) )
}

m2 <- fisheries_matrices(states, actions, obs, reward_fn, f, sigma_g, sigma_m)

models <- list(m1,m2)
model_prior <- c(1, 0.)
```


## POMDP solution, model 1

```{r}
soln_1 <- pomdp_solve(m1$transition, m1$observation, m1$reward, discount, precision = 1)
```


```{r}
ggplot(soln_1, aes(states[state], states[state] - actions[policy])) + geom_point()
```


## Planning solution

```{r}
soln <- pomdp_planning(models, discount, model_prior, verbose = TRUE, mc.cores = 1L, precision = 1)
```


```{r}

ggplot(soln, aes(states[state], states[state] - actions[policy])) + geom_point()
```

